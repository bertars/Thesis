{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from typing import Union, Tuple, List, Dict\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 14\n",
    "MEDIUM_SIZE = 16\n",
    "BIGGER_SIZE = 18\n",
    "\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM = 'sockshop'\n",
    "DATA_FOLDER = Path(f\"../AD/anomaly_detection_models\")\n",
    "RESULTS_FOLDER = \"statistics.csv\"\n",
    "\n",
    "AD_MODELS = [\"birch\", \"iforest\", \"knn\", \"svm\"]\n",
    "AD_METRICS = ['Precision', 'Recall', 'F-Score']\n",
    "RCA_METRICS = ['level_1', 'level_2', 'level_3']\n",
    "\n",
    "SOCKSHOP_SERVICES = ['front-end', 'orders', 'carts', 'shipping', 'catalogue', 'payment', 'user']\n",
    "SYSTEM_SERVICES = {'sockshop' : SOCKSHOP_SERVICES}\n",
    "DESCRIPTIVE_STATISTICS_FOLDER = Path(f\"Descriptive statistics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the all folder names within specified directory\n",
    "def get_folder_names(directory):\n",
    "  folder_names = [folder for folder in os.listdir(directory) if os.path.isdir(os.path.join(directory, folder))]\n",
    "  return folder_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This only retrieves the ground truth ranges for Energy Anomalies\n",
    "def get_energy_anomaly_gt_ranges(gt_file):\n",
    "  gt_df = pd.read_csv(gt_file)\n",
    "  gt_energy_metrics = {}\n",
    "  gt_energy_metrics[\"normal_segments\"] = {}\n",
    "  gt_energy_metrics[\"anomalous_segments\"] = {}\n",
    "\n",
    "  for col in gt_df.columns:\n",
    "    if not col.endswith(\"_energy_Anomaly\"):\n",
    "      continue\n",
    "    gt_energy_metrics[\"normal_segments\"][col] = []\n",
    "    gt_energy_metrics[\"anomalous_segments\"][col] = []\n",
    "\n",
    "    normal_start = None\n",
    "    anomalous_start = None\n",
    "\n",
    "    for index, value in gt_df[col].items():\n",
    "      if value == 0:  # value of 0 indicates normal data point\n",
    "        if normal_start is None:\n",
    "          normal_start = index\n",
    "        else:\n",
    "          continue\n",
    "\n",
    "        if anomalous_start != None:\n",
    "          gt_energy_metrics[\"anomalous_segments\"][col].append((anomalous_start, index - 1))\n",
    "          anomalous_start = None\n",
    "\n",
    "      if value == 1:  # value of 1 indicates anomalous data point\n",
    "        if anomalous_start is None:\n",
    "          anomalous_start = index\n",
    "        else:\n",
    "          continue\n",
    "\n",
    "        if normal_start != None:\n",
    "          gt_energy_metrics[\"normal_segments\"][col].append((normal_start, index - 1))\n",
    "          normal_start = None\n",
    "\n",
    "    if normal_start != None:\n",
    "      gt_energy_metrics[\"normal_segments\"][col].append((normal_start, len(gt_df[col])))\n",
    "    elif anomalous_start != None:\n",
    "      gt_energy_metrics[\"anomalous_segments\"][col].append((anomalous_start, len(gt_df[col])))\n",
    "\n",
    "  return gt_energy_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_stats(results_path, gt_ranges, ad_results):\n",
    "  # Create new directory if they do not exist\n",
    "  directory = os.path.dirname(results_path)\n",
    "  if not os.path.exists(directory):\n",
    "      os.makedirs(directory)\n",
    "  print(results_path)\n",
    "\n",
    "  # Save data to a csv file\n",
    "  with open(results_path, mode='w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    header = [\"service_name\", \"true_positives\", \"false_positives\", \"false_negatives\"]\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for col in ad_results.columns:\n",
    "      if not col.endswith(\"_Anomaly\"):\n",
    "        continue\n",
    "\n",
    "      true_positives = 0\n",
    "      false_positives = 0\n",
    "      false_negatives = 0\n",
    "      \n",
    "      col_service = col.split(\"_\")[0]\n",
    "      gt_col = col_service + \"_energy_Anomaly\"\n",
    "      \n",
    "      \n",
    "      ad_metric_col = ad_results[col]\n",
    "      \n",
    "      for normal_range in gt_ranges[\"normal_segments\"][gt_col]:\n",
    "        range_start = normal_range[0]\n",
    "        range_end = normal_range[1] + 1\n",
    "        ad_range_values = ad_metric_col[range_start:range_end]\n",
    "\n",
    "        # if one value within the range is marked as an anomaly then we consider it as a false positive\n",
    "        if not ad_range_values.all() == 0:\n",
    "          false_positives += 1\n",
    "\n",
    "      for anomalous_range in gt_ranges[\"anomalous_segments\"][gt_col]:\n",
    "        range_start = anomalous_range[0]\n",
    "        range_end = anomalous_range [1] + 1\n",
    "        ad_range_values = ad_metric_col[range_start:range_end]\n",
    "\n",
    "        if ad_range_values.any() == 1:\n",
    "          true_positives += 1\n",
    "        else:\n",
    "          false_negatives += 1\n",
    "\n",
    "      data_row = [col, true_positives, false_positives, false_negatives]\n",
    "      writer.writerow(data_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision(tp, fp):\n",
    "  if (tp + fp) == 0:\n",
    "    return 0\n",
    "  return round(tp / (tp + fp),3)\n",
    "\n",
    "\n",
    "def calculate_recall(tp, fn):\n",
    "  if (tp + fn) == 0:\n",
    "    return 0\n",
    "  return round(tp / (tp + fn),3)\n",
    "\n",
    "\n",
    "def calculate_fscore(precision, recall):\n",
    "  if precision + recall == 0:\n",
    "    return 0\n",
    "  fscore = 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "  return round(fscore,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_performance_metrics(results_folder):\n",
    "  # Create new directory if they do not exist\n",
    "  if not os.path.exists(results_folder):\n",
    "      os.makedirs(results_folder)\n",
    "\n",
    "  # Get a list of CSV file paths\n",
    "  csv_files = [os.path.join(results_folder, file) for file in os.listdir(results_folder) if file.endswith('.csv')]\n",
    " \n",
    "  for file in csv_files:\n",
    "    if not 'statistics' in file:\n",
    "      continue\n",
    "    model = file.split('\\\\')[-1].split('_')[0] \n",
    "    if not model in AD_MODELS:\n",
    "      continue\n",
    "    df = pd.read_csv(file)\n",
    "    for i in range(0,len(df)):\n",
    "      df.loc[i,'precision'] = calculate_precision(df.loc[i,'true_positives'], df.loc[i,'false_positives'])\n",
    "      df.loc[i,'recall'] = calculate_recall(df.loc[i,'true_positives'], df.loc[i,'false_negatives'])\n",
    "      df.loc[i,'f1score'] = calculate_fscore(df.loc[i,'precision'], df.loc[i,'recall'])\n",
    "\n",
    "    df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_ad(trial_folder):\n",
    "  \n",
    "  for ad_model in AD_MODELS:\n",
    "      ad_file = os.path.join(trial_folder, f'{ad_model}_results.csv')\n",
    "      ad_results = pd.read_csv(ad_file)\n",
    "      gt_ranges = get_energy_anomaly_gt_ranges(os.path.join(trial_folder, 'ground_truth.csv'))\n",
    "      results_file = os.path.join(trial_folder, f'{ad_model}_{RESULTS_FOLDER}')\n",
    "      generate_model_stats(results_file, gt_ranges, ad_results)\n",
    "  generate_performance_metrics(trial_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats():\n",
    "  # Anomaly detection\n",
    "  scenarios = get_folder_names(DATA_FOLDER)\n",
    "\n",
    "  for scenario in scenarios:\n",
    "    service_folder = os.path.join(DATA_FOLDER, scenario)\n",
    "    stressors = get_folder_names(service_folder)\n",
    "\n",
    "    for stressor in stressors:\n",
    "      stressor_folder = os.path.join(service_folder, stressor)\n",
    "      users = get_folder_names(stressor_folder)\n",
    "\n",
    "      for user in users:\n",
    "        user_folder = os.path.join(stressor_folder, user)\n",
    "        scenarios = get_folder_names(user_folder)\n",
    "        \n",
    "        for scenario in scenarios:          \n",
    "            scenario_folder = os.path.join(user_folder, scenario)\n",
    "            time_windows = get_folder_names(scenario_folder)\n",
    "            \n",
    "            for time in time_windows:\n",
    "              time_folder = os.path.join(scenario_folder, time)\n",
    "              trials = get_folder_names(time_folder)\n",
    "              \n",
    "              for trial in trials:\n",
    "                  trial_folder = os.path.join(time_folder, trial)\n",
    "                  \n",
    "                  get_stats_ad(trial_folder)\n",
    "                  \n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overall_AD_and_RCA_data(services, ad_stats, rca_stats):\n",
    "  \n",
    "    for service in services:\n",
    "        service_folder = os.path.join(DATA_FOLDER, service)\n",
    "        stressors = get_folder_names(service_folder)\n",
    "        \n",
    "        for stressor in stressors:\n",
    "            stressor_folder = os.path.join(service_folder, stressor)\n",
    "            users = get_folder_names(stressor_folder)\n",
    "            \n",
    "            for user in users:\n",
    "              user_folder = os.path.join(stressor_folder, user)\n",
    "              scenarios = get_folder_names(user_folder)\n",
    "            \n",
    "              for scenario in scenarios:                  \n",
    "                scenario_folder = os.path.join(user_folder, scenario)\n",
    "                time_windows = get_folder_names(scenario_folder)\n",
    "                \n",
    "                for time in time_windows:\n",
    "                  \n",
    "                  if not time in rca_stats:\n",
    "                    rca_stats[time] = {}\n",
    "                                        \n",
    "                  if not time in ad_stats:\n",
    "                    ad_stats[time] = {}\n",
    "                    \n",
    "                  time_folder = os.path.join(scenario_folder, time)\n",
    "                  trials = get_folder_names(time_folder)\n",
    "\n",
    "                  for trial in trials:           \n",
    "                    trial_folder = os.path.join(time_folder, trial)\n",
    "                    \n",
    "                    for file in os.listdir(trial_folder):\n",
    "                      if 'statistics' not in file:\n",
    "                        continue\n",
    "                      \n",
    "                      model_df = pd.read_csv(os.path.join(trial_folder,file))\n",
    "                      model = file.split('_')[0]\n",
    "                      \n",
    "                      # Anomaly detection\n",
    "                      if model in AD_MODELS:  \n",
    "                        if not stressor in ad_stats[time]:\n",
    "                          ad_stats[time][model] = {}\n",
    "                            \n",
    "                        precision_series =  model_df['precision'].values\n",
    "                        recall_series =  model_df['recall'].values\n",
    "                        f1score_series =  model_df['f1score'].values                    \n",
    "                            \n",
    "                        if not \"Precision\" in ad_stats[time][model] :\n",
    "                            ad_stats[time][model] [\"Precision\"] = precision_series\n",
    "                        else:\n",
    "                            existing_precision = ad_stats[time][model] [\"Precision\"]\n",
    "                            ad_stats[time][model] [\"Precision\"] = np.concatenate((existing_precision, precision_series), axis = None)\n",
    "                                                  \n",
    "                        if not \"Recall\" in ad_stats[time][model] :                    \n",
    "                            ad_stats[time][model] [\"Recall\"] = recall_series\n",
    "                        else:\n",
    "                            existing_recall = ad_stats[time][model] [\"Recall\"]\n",
    "                            ad_stats[time][model] [\"Recall\"] = np.concatenate((existing_recall, recall_series), axis = None)\n",
    "                            \n",
    "                        if not \"F-Score\" in ad_stats[time][model] :\n",
    "                            ad_stats[time][model] [\"F-Score\"] = f1score_series\n",
    "                        else:\n",
    "                            existing_f1score = ad_stats[time][model] [\"F-Score\"]\n",
    "                            ad_stats[time][model] [\"F-Score\"] = np.concatenate((existing_f1score, f1score_series), axis = None)\n",
    "                    \n",
    "    return ad_stats"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
